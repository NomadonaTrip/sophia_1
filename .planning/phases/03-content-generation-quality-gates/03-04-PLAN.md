---
phase: 03-content-generation-quality-gates
plan: 04
type: execute
wave: 1
depends_on: ["03-03"]
files_modified:
  - backend/src/sophia/content/service.py
  - backend/tests/test_content_lifecycle.py
autonomous: true
gap_closure: true
requirements: [CONT-08]

must_haves:
  truths:
    - "should_apply_ai_label is called for every non-rejected draft after quality gates pass in generate_content_batch"
    - "apply_ai_label sets has_ai_label=True on drafts where labeling is mandated"
    - "regenerate_draft calls should_apply_ai_label and apply_ai_label after quality gates pass on regenerated copy"
    - "Text-only Meta posts default to has_ai_label=False (current policy)"
    - "Drafts with AI-generated photorealistic images get has_ai_label=True"
  artifacts:
    - path: "backend/src/sophia/content/service.py"
      provides: "AI label wiring in generate_content_batch and regenerate_draft"
      contains: "should_apply_ai_label"
    - path: "backend/tests/test_content_lifecycle.py"
      provides: "Integration tests proving AI label runs in the content pipeline"
      contains: "test_ai_label_applied_in_batch"
  key_links:
    - from: "backend/src/sophia/content/service.py"
      to: "backend/src/sophia/content/ai_label.py"
      via: "import should_apply_ai_label, apply_ai_label"
      pattern: "from sophia\\.content\\.ai_label import"
---

<objective>
Wire AI-assisted labeling into the content pipeline to close CONT-08 verification gap.

Purpose: ai_label.py exists and is tested in isolation but is never called from service.py. Every draft exits the pipeline with has_ai_label=False regardless of platform/content type, silently skipping labeling requirements for AI-generated photorealistic images. This plan wires should_apply_ai_label and apply_ai_label into both generate_content_batch (after quality gates, before persistence) and regenerate_draft (after quality gates pass on regenerated copy).

Output: service.py imports and calls AI label functions; integration tests prove the wiring works end-to-end.
</objective>

<execution_context>
@/home/nomad/.claude/get-shit-done/workflows/execute-plan.md
@/home/nomad/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-content-generation-quality-gates/03-03-SUMMARY.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From backend/src/sophia/content/ai_label.py:
```python
def should_apply_ai_label(
    platform: str, content_type: str, has_ai_image: bool = False
) -> bool:
    """Returns True if AI label should be applied."""

def apply_ai_label(draft: "ContentDraft") -> "ContentDraft":
    """Sets draft.has_ai_label = True. Returns the modified draft."""
```

From backend/src/sophia/content/service.py (current imports, line 40):
```python
from sophia.content.quality_gates import run_pipeline as run_quality_gates
```

Current generate_content_batch flow (lines 158-210):
- Step 7: Run quality gates on each draft (lines 158-177)
- Step 8: Filter rejected drafts (lines 178-201)
- Step 9: Rank active drafts (line 204)
- Step 10: Persist ALL drafts (lines 207-210)
AI label check should go between Step 8 (filtering) and Step 9 (ranking) -- apply to active (non-rejected) drafts only.

Current regenerate_draft flow (lines 700-705):
- Run quality gates (line 703)
- Update gate_status and gate_report (lines 704-705)
- If rejected, revert copy (lines 708-710)
AI label check should go after the rejection check -- only apply to drafts that passed gates.
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire AI label into service.py and add integration tests</name>
  <files>backend/src/sophia/content/service.py, backend/tests/test_content_lifecycle.py</files>
  <action>
    **In service.py:**

    1. Add import at the top (after line 40, with the other content module imports):
       ```python
       from sophia.content.ai_label import apply_ai_label, should_apply_ai_label
       ```

    2. In `generate_content_batch`, add AI label application between Step 8 (filter rejected) and Step 9 (rank). Insert after line 182 (`rejected_drafts = ...`) and before the all-rejected check. Apply to ALL non-rejected drafts:
       ```python
       # Step 8b: Apply AI-assisted labeling where mandated (CONT-08)
       for draft in active_drafts:
           has_ai_image = bool(draft.image_prompt and "photorealistic" in (draft.image_prompt or "").lower())
           if should_apply_ai_label(draft.platform, draft.content_type, has_ai_image=has_ai_image):
               apply_ai_label(draft)
       ```
       Note: `has_ai_image` detection uses the image_prompt field. Since Sophia generates AI image prompts (not stock photos), the check looks for "photorealistic" in the prompt to determine if the resulting image would be photorealistic (triggering the label requirement). For text-only posts without photorealistic image prompts, the label defaults OFF per current Meta policy.

    3. In `regenerate_draft`, add AI label application after the rejection check (after line 710). Only apply to drafts that passed quality gates:
       ```python
       # Apply AI-assisted labeling on regenerated draft (CONT-08)
       if report.status != "rejected":
           has_ai_image = bool(draft.image_prompt and "photorealistic" in (draft.image_prompt or "").lower())
           if should_apply_ai_label(draft.platform, draft.content_type, has_ai_image=has_ai_image):
               apply_ai_label(draft)
       ```

    **In test_content_lifecycle.py:**

    Add integration tests proving the wiring works. Add these tests to the existing test file (find an appropriate class or create a new `TestAILabelPipelineIntegration` class):

    1. `test_ai_label_applied_in_batch_with_photorealistic_image` -- Create a draft with a photorealistic image prompt, mock quality gates to pass, verify has_ai_label=True after generate_content_batch.

    2. `test_ai_label_not_applied_text_only_meta` -- Create a text-only draft (no photorealistic image prompt), verify has_ai_label remains False after generate_content_batch (current Meta policy: text-only = no label).

    3. `test_ai_label_applied_in_regeneration` -- Create a draft with photorealistic image prompt, run regenerate_draft with passing gates, verify has_ai_label=True on the returned draft.

    4. `test_ai_label_not_applied_to_rejected_drafts` -- Create a draft that fails quality gates (rejected), verify has_ai_label remains False (labels only apply to drafts that pass gates).

    Follow existing test patterns: use db_session fixture, mock quality gates with `unittest.mock.patch`, and create draft objects using the existing ContentDraft model with required fields.
  </action>
  <verify>
    <automated>cd /mnt/e/TOOLMAKER/PYTHON/sophia/backend && python -m pytest tests/test_content_lifecycle.py -x -v -k "ai_label" 2>&1 | tail -20</automated>
  </verify>
  <done>
    - service.py imports should_apply_ai_label and apply_ai_label from ai_label.py
    - generate_content_batch calls AI label check on non-rejected drafts after quality gates
    - regenerate_draft calls AI label check on drafts that pass quality gates
    - Text-only Meta posts remain has_ai_label=False (default OFF)
    - Photorealistic image drafts get has_ai_label=True
    - Rejected drafts do NOT get AI labels applied
    - All existing 126 tests still pass
    - New integration tests confirm the wiring
  </done>
</task>

</tasks>

<verification>
1. `cd /mnt/e/TOOLMAKER/PYTHON/sophia/backend && python -m pytest tests/ -x -v 2>&1 | tail -30` -- All tests pass (existing 126 + new integration tests)
2. `grep -n "should_apply_ai_label\|apply_ai_label" backend/src/sophia/content/service.py` -- Both functions imported and called in generate_content_batch and regenerate_draft
3. `grep -c "from sophia.content.ai_label import" backend/src/sophia/content/service.py` -- Returns 1 (import present)
</verification>

<success_criteria>
- CONT-08 gap closed: AI-assisted labeling is wired into the content pipeline
- The key link ai_label.py -> service.py exists (import + calls in both generate_content_batch and regenerate_draft)
- Text-only Meta posts default OFF per locked decision
- All 126+ tests pass with new integration tests added
</success_criteria>

<output>
After completion, create `.planning/phases/03-content-generation-quality-gates/03-04-SUMMARY.md`
</output>
